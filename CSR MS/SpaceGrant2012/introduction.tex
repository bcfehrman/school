Computer vision has long been performed in a flat, two-dimensional world. The real world, however, is not two-dimensional. Projecting the world onto a plane has inherent consequences such as ambiguities when trying to recognize objects within a scene. For instance, a picture of an object could be mistaken for the real life item. To overcome the inaccuracies of flattening the world there has been a large effort towards algorithms using three and four dimensional point cloud data. Some of the fuel for the interest has been the recent availability of low cost natural interface devices such as the Microsoft Kinect sensor which can scan the environment and provide a cloud point representation of what it sees. These devices can easily be fitted to robots and ultimately used for tasks such as object recognition within a scene. Here the goal is to improve upon existing object recognition algorithms by investigating artificial intelligence techniques such as evolving a recurrent neural network that can be used to identify items that are encountered. 